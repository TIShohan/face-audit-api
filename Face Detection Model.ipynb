{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6369cc5-8e3c-4dc3-8436-2a9c146e213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in CSV: 24909\n",
      "Rows already processed (skipped): 24872\n",
      "Rows to be processed (Empty + 'DOWNLOAD_ERROR'): 37\n",
      "\n",
      "Dividing 37 rows into 1 batches of up to 2000 rows each.\n",
      "------------------------------------------------------------\n",
      "ðŸš€ Starting Batch 1/1 (Size: 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1 Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:01<00:00, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "âœ… Batch 1 Summary (Processed 37 rows)\n",
      "Batch GOOD Faces        : 0\n",
      "Batch NO FACE Images    : 0\n",
      "Batch DOWNLOAD FAILURES : 37\n",
      "------------------------------------------------------------\n",
      "ðŸ’¾ **CSV checkpoint saved successfully** after Batch 1.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "======================================================================\n",
      "âœ… ALL BATCHES COMPLETE!\n",
      "Total Rows in CSV       : 24909\n",
      "Rows Processed in Run   : 37\n",
      "----------------------------------------------------------\n",
      "GRAND TOTALS (NEW RESULTS):\n",
      "Total GOOD Faces        : 0\n",
      "Total NO FACE Images    : 0\n",
      "Total DOWNLOAD FAILURES : 37\n",
      "NO FACE images saved to : E:\\BAT eCRM - Main Folder\\eCRM_Audit_Monthly Report\\November\\Manual\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Version works best and reliable\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# ==========================================\n",
    "# ============== CONFIGURATION =============\n",
    "# ==========================================\n",
    "csv_path = r\"E:\\BAT eCRM - Main Folder\\eCRM_Audit_Monthly Report\\November\\Check in Image Audit_November_2025_Raw- Main File.csv\"\n",
    "manual_folder = r\"E:\\BAT eCRM - Main Folder\\eCRM_Audit_Monthly Report\\November\\Manual\"\n",
    "num_threads = 6 \n",
    "\n",
    "# --- NEW CONFIGURABLE SETTINGS ---\n",
    "DOWNLOAD_TIMEOUT = 20         \n",
    "MEDIAPIPE_CONF_THRESH = 0.80  \n",
    "DNN_CONF_THRESH = 0.70        \n",
    "BATCH_SIZE = 2000 # NEW: Number of rows to process before saving and summarizing\n",
    "# ==========================================\n",
    "\n",
    "os.makedirs(manual_folder, exist_ok=True)\n",
    "\n",
    "# === Initialize MediaPipe & OpenCV DNN (Moved up for global access) ===\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "model_dir = r\"C:\\Users\\mdtai\\Audit - BAT\\Face Detection Report\"\n",
    "prototxt_path = os.path.join(model_dir, \"deploy.prototxt.txt\")\n",
    "model_path = os.path.join(model_dir, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "\n",
    "# === Functions (No Change) ===\n",
    "def download_image(url):\n",
    "    try:\n",
    "        # Uses the configurable DOWNLOAD_TIMEOUT\n",
    "        response = requests.get(url, timeout=DOWNLOAD_TIMEOUT) \n",
    "        response.raise_for_status()\n",
    "        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        return cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def detect_with_dnn(image):\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,\n",
    "                                 (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    # Uses the configurable DNN_CONF_THRESH\n",
    "    return np.max(detections[0, 0, :, 2]) > DNN_CONF_THRESH\n",
    "\n",
    "def process_row(row):\n",
    "    img_url = row.get(\"Check-In Photo\")\n",
    "    id_val = row.get(\"id\", row.name) \n",
    "\n",
    "    if pd.isna(img_url) or str(img_url).strip() == \"\":\n",
    "        return row.name, \"Skipped (empty URL)\", \"\"\n",
    "\n",
    "    image = download_image(str(img_url))\n",
    "\n",
    "    if image is None:\n",
    "        return row.name, \"DOWNLOAD_ERROR\", \"Image could not be downloaded\"\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Uses the configurable MEDIAPIPE_CONF_THRESH\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=MEDIAPIPE_CONF_THRESH) as face_detector:\n",
    "        results = face_detector.process(image_rgb)\n",
    "        face_found = results.detections is not None and len(results.detections) > 0\n",
    "\n",
    "    if not face_found:\n",
    "        face_found = detect_with_dnn(image)\n",
    "\n",
    "    if face_found:\n",
    "        return row.name, \"GOOD\", \"\"\n",
    "    else:\n",
    "        save_path = os.path.join(manual_folder, f\"{id_val}_NOFACE.jpg\")\n",
    "        cv2.imwrite(save_path, image)\n",
    "        return row.name, \"NO FACE\", f\"Saved: {save_path}\"\n",
    "\n",
    "# === Main Execution Logic with Batching ===\n",
    "\n",
    "# Load the entire DataFrame once\n",
    "df = pd.read_csv(csv_path)\n",
    "original_df_len = len(df)\n",
    "df[\"Face_Status\"] = df[\"Face_Status\"].astype(str).replace('nan', '', regex=False)\n",
    "\n",
    "# Identify rows to process (Empty/NaN or DOWNLOAD_ERROR)\n",
    "rows_to_process = df[\n",
    "    (df[\"Face_Status\"].isna()) | \n",
    "    (df[\"Face_Status\"].astype(str).str.strip() == '') | \n",
    "    (df[\"Face_Status\"] == 'DOWNLOAD_ERROR')\n",
    "]\n",
    "\n",
    "# We iterate over the indices of the rows that need processing\n",
    "processing_indices = rows_to_process.index.tolist()\n",
    "processing_df_len = len(processing_indices)\n",
    "\n",
    "print(f\"Total rows in CSV: {original_df_len}\")\n",
    "print(f\"Rows already processed (skipped): {original_df_len - processing_df_len}\")\n",
    "print(f\"Rows to be processed (Empty + 'DOWNLOAD_ERROR'): {processing_df_len}\\n\")\n",
    "\n",
    "if processing_df_len == 0:\n",
    "    print(\"âœ… All rows have already been processed. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = math.ceil(processing_df_len / BATCH_SIZE)\n",
    "\n",
    "# Global counters for summary (These track the NEW results from the current run)\n",
    "total_good_count = 0\n",
    "total_noface_count = 0\n",
    "total_download_err_count = 0\n",
    "total_processed_in_run = 0\n",
    "\n",
    "print(f\"Dividing {processing_df_len} rows into {num_batches} batches of up to {BATCH_SIZE} rows each.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for i in range(num_batches):\n",
    "    start_index = i * BATCH_SIZE\n",
    "    end_index = min((i + 1) * BATCH_SIZE, processing_df_len)\n",
    "    \n",
    "    # Get the indices for the current batch\n",
    "    current_batch_indices = processing_indices[start_index:end_index]\n",
    "    \n",
    "    # Use .loc to get the actual rows from the original DataFrame\n",
    "    current_batch_df = df.loc[current_batch_indices].copy()\n",
    "    batch_size = len(current_batch_df)\n",
    "\n",
    "    # Reset batch counters\n",
    "    batch_good_count = 0\n",
    "    batch_noface_count = 0\n",
    "    batch_download_err_count = 0\n",
    "\n",
    "    print(f\"ðŸš€ Starting Batch {i + 1}/{num_batches} (Size: {batch_size})\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        # Map the future result back to the original index in df\n",
    "        future_to_original_idx = {\n",
    "            executor.submit(process_row, row): original_idx\n",
    "            for original_idx, row in current_batch_df.iterrows()\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(as_completed(future_to_original_idx), total=batch_size, desc=f\"Batch {i + 1} Progress\"):\n",
    "            original_idx = future_to_original_idx[future] \n",
    "            total_processed_in_run += 1\n",
    "            \n",
    "            try:\n",
    "                processing_idx, status, log_msg = future.result() \n",
    "                \n",
    "                # --- CRITICAL: Update the original DataFrame directly ---\n",
    "                df.at[original_idx, \"Face_Status\"] = status \n",
    "                \n",
    "                # Tally results\n",
    "                if status == \"GOOD\":\n",
    "                    batch_good_count += 1\n",
    "                elif status == \"NO FACE\":\n",
    "                    batch_noface_count += 1\n",
    "                elif status == \"DOWNLOAD_ERROR\":\n",
    "                    batch_download_err_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                df.at[original_idx, \"Face_Status\"] = \"SYSTEM_ERROR\"\n",
    "                print(f\"\\n[SYSTEM ERROR] Row Index {original_idx}: {e}\")\n",
    "\n",
    "    # === UPDATE TOTAL COUNTERS & BATCH SUMMARY ===\n",
    "    total_good_count += batch_good_count\n",
    "    total_noface_count += batch_noface_count\n",
    "    total_download_err_count += batch_download_err_count\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"âœ… Batch {i + 1} Summary (Processed {batch_size} rows)\")\n",
    "    print(f\"Batch GOOD Faces        : {batch_good_count}\")\n",
    "    print(f\"Batch NO FACE Images    : {batch_noface_count}\")\n",
    "    print(f\"Batch DOWNLOAD FAILURES : {batch_download_err_count}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # === SAVE CHECKPOINT ===\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"ðŸ’¾ **CSV checkpoint saved successfully** after Batch {i + 1}.\")\n",
    "    print(\"-\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "# === FINAL SUMMARY ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ… ALL BATCHES COMPLETE!\")\n",
    "print(f\"Total Rows in CSV       : {original_df_len}\")\n",
    "print(f\"Rows Processed in Run   : {total_processed_in_run}\")\n",
    "print(f\"----------------------------------------------------------\")\n",
    "print(f\"GRAND TOTALS (NEW RESULTS):\")\n",
    "print(f\"Total GOOD Faces        : {total_good_count}\")\n",
    "print(f\"Total NO FACE Images    : {total_noface_count}\")\n",
    "print(f\"Total DOWNLOAD FAILURES : {total_download_err_count}\")\n",
    "print(f\"NO FACE images saved to : {manual_folder}\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
